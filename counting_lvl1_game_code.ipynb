{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"YOUR KEY HERE\")\n",
    "\n",
    "# Model settings\n",
    "model = \"o3-2025-04-16\"\n",
    "\n",
    "# Meta-rule configuration\n",
    "ORDINAL_WORDS = [\"first\", \"second\", \"third\", \"fourth\", \"fifth\"]\n",
    "MAX_CONTEXT_SIZE = 3\n",
    "\n",
    "# Transformation types with meta-rules - for prompt 2, comment out the description\n",
    "TRANSFORM_TYPES = {\n",
    "    'succ': {\n",
    "        'name': 'Successorship',\n",
    "        'description': 'The last letter changes to the next letter in the alphabet',\n",
    "        'rule_number': 1\n",
    "    },\n",
    "    'pred': {\n",
    "        'name': 'Predecessorship', \n",
    "        'description': 'The first letter changes to the previous letter in the alphabet',\n",
    "        'rule_number': 2\n",
    "    },\n",
    "    'add_letter': {\n",
    "        'name': 'Adding a letter',\n",
    "        'description': 'The next letter in the alphabet after the last letter is added to the end',\n",
    "        'rule_number': 3\n",
    "    },\n",
    "    'remove_redundant': {\n",
    "        'name': 'Removing redundant character',\n",
    "        'description': 'If there are duplicate letters, the first duplicate found is removed',\n",
    "        'rule_number': 4\n",
    "    },\n",
    "    'counting': {\n",
    "        'name': 'Counting',\n",
    "        'description': 'Count the number of letters in the sequence',\n",
    "        'rule_number': 5\n",
    "    }\n",
    "}\n",
    "\n",
    "# Meta-rule answers file for alphabet game\n",
    "ALPHABET_META_ANSWERS_FILE = 'alphabet_meta_answers.json'\n",
    "\n",
    "def create_system_prompt():\n",
    "    \"\"\"Create the system prompt with all rule explanations and meta-rules\"\"\"\n",
    "    prompt = \"\"\"**Rule Explanations:**\n",
    "**Rule 1 (Successorship):** The last letter changes to the next letter in the alphabet (e.g., abb -> abc; moose -> moosf; vwxyz -> vwxya)\n",
    "**Rule 2 (Predecessorship):** The first letter changes to the previous letter in the alphabet (e.g., abb -> zbb; moose -> loose; vwxyz -> uwxyz)  \n",
    "**Rule 3 (Adding a letter):** The next letter in the alphabet after the last letter is added to the end of the sequence (e.g., abb -> abbc; moose -> moosef; vwxyz -> vwxyza)\n",
    "**Rule 4 (Removing redundant character):** If there are duplicate letters, the first duplicate found is removed (e.g., abb -> ab; moose -> mose; vwxyz -> vwxyz)\n",
    "**Rule 5 (Counting):** Count the number of letters in the sequence (e.g., abb -> 3; moose -> 5; vwxyz -> 5)\n",
    "\n",
    "The base rule of the game is rule 1. Unless otherwise specified, this is the rule you apply.\n",
    "**Base Rule:** Use **Rule 1** as the default unless instructed otherwise by the meta-rules.\n",
    "**Meta rule 1**: When you encounter an **ordinal number**, **switch the base rule** to the corresponding numbered rule (\"first\" apply rule 1, \"second\" apply rule 2, \"third\" apply rule 3, \"fourth\" apply rule 4, \"fifth\" apply rule 5). Apply this new rule from that point onward until another ordinal number appears, at which point you update the base rule again.\n",
    "\n",
    "At the end of your response, please provide your final answer in this exact format: Answer: [transformed result]\"\"\"\n",
    "    \n",
    "    return prompt\n",
    "#in following comment, prompt 2\n",
    "'''\n",
    "def create_system_prompt():\n",
    "    \"\"\"Create the system prompt with all rule explanations and meta-rules\"\"\"\n",
    "    prompt = \"\"\"**Rule Explanations:**\n",
    "**Rule 1 (Successorship):** e.g., abb -> abc; moose -> moosf; vwxyz -> vwxya\n",
    "**Rule 2 (Predecessorship):** e.g., abb -> zbb; moose -> loose; vwxyz -> uwxyz\n",
    "**Rule 3 (Adding letter):** e.g., abb -> abbc; moose -> moosef; vwxyz -> vwxyza\n",
    "**Rule 4 (Removing redundant character):** e.g., abb -> ab; moose -> mose; vwxwyz -> vwxyz\n",
    "**Rule 5 (Counting):** e.g., abb -> 3; moose -> 5; vwxyz -> 5\n",
    "\n",
    "Base Rule: Use Rule 1 as the default unless instructed otherwise by the meta-rules.\n",
    "**Meta rule 1**: When you encounter an ordinal number, switch the base rule to the corresponding numbered rule (\"first\" apply rule 1, \"second\" apply rule 2, \"third\" apply rule 3, \"fourth\" apply rule 4, \"fifth\" apply rule 5). Apply this new rule from that point onward until another ordinal number appears, at which point you update the base rule again.\n",
    "\n",
    "Keep the reasoning output to a minimum. At the end of your response, please provide your final answer in this EXACT format, do not change the format at all: Answer: [transformed result]\"\"\"\n",
    "    \n",
    "    return prompt\n",
    "    '''\n",
    "\n",
    "def load_alphabet_meta_answers():\n",
    "    \"\"\"Load predefined transformations for ordinal words under different rules\"\"\"\n",
    "    try:\n",
    "        with open(ALPHABET_META_ANSWERS_FILE, 'r') as f:\n",
    "            return json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        # Return default transformations if file doesn't exist\n",
    "        return {\n",
    "            \"first\": {\n",
    "                \"succ\": \"firsu\",\n",
    "                \"pred\": \"eirst\",\n",
    "                \"add_letter\": \"firstu\",\n",
    "                \"remove_redundant\": \"first\",\n",
    "                \"counting\": \"5\"\n",
    "            },\n",
    "            \"second\": {\n",
    "                \"succ\": \"secone\",\n",
    "                \"pred\": \"recond\",\n",
    "                \"add_letter\": \"seconde\",\n",
    "                \"remove_redundant\": \"second\",\n",
    "                \"counting\": \"6\"\n",
    "            },\n",
    "            \"third\": {\n",
    "                \"succ\": \"thire\",\n",
    "                \"pred\": \"shird\",\n",
    "                \"add_letter\": \"thirde\",\n",
    "                \"remove_redundant\": \"third\",\n",
    "                \"counting\": \"5\"\n",
    "            },\n",
    "            \"fourth\": {\n",
    "                \"succ\": \"fourti\",\n",
    "                \"pred\": \"eourth\",\n",
    "                \"add_letter\": \"fourthi\",\n",
    "                \"remove_redundant\": \"fourth\",\n",
    "                \"counting\": \"6\"\n",
    "            },\n",
    "            \"fifth\": {\n",
    "                \"succ\": \"fifti\",\n",
    "                \"pred\": \"eifth\",\n",
    "                \"add_letter\": \"fifthi\",\n",
    "                \"remove_redundant\": \"fith\",\n",
    "                \"counting\": \"5\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "def insert_ordinal_word(sequence, probability=0.1):\n",
    "    \"\"\"Randomly replace the sequence with 1 ordinal word with given probability\"\"\"\n",
    "    if random.random() > probability:\n",
    "        return sequence, []\n",
    "    \n",
    "    # Select exactly 1 ordinal word to replace the entire sequence\n",
    "    selected_word = random.choice(ORDINAL_WORDS)\n",
    "    \n",
    "    return selected_word, [selected_word]\n",
    "\n",
    "def determine_active_transform(inserted_words, current_transform):\n",
    "    \"\"\"Determine which transformation should be active based on inserted ordinal words\"\"\"\n",
    "    if not inserted_words:\n",
    "        return current_transform\n",
    "    \n",
    "    # Use the last ordinal word to determine the transformation\n",
    "    transform_mapping = {\n",
    "        \"first\": \"succ\",           # Rule 1\n",
    "        \"second\": \"pred\",          # Rule 2\n",
    "        \"third\": \"add_letter\",     # Rule 3\n",
    "        \"fourth\": \"remove_redundant\", # Rule 4\n",
    "        \"fifth\": \"counting\"        # Rule 5\n",
    "    }\n",
    "    \n",
    "    return transform_mapping.get(inserted_words[-1], current_transform)\n",
    "\n",
    "def get_transform_result_for_ordinal(word, transform_type, meta_answers):\n",
    "    \"\"\"Get the transformation result for an ordinal word under a specific transformation\"\"\"\n",
    "    if word in meta_answers and transform_type in meta_answers[word]:\n",
    "        return meta_answers[word][transform_type]\n",
    "    \n",
    "    # Fallback transformations\n",
    "    fallback_results = {\n",
    "        \"succ\": word + \"t\",  # Add 't' as successor\n",
    "        \"pred\": \"a\" + word,  # Prepend 'a' as predecessor\n",
    "        \"add_letter\": word + word[-1],  # Duplicate last letter\n",
    "        \"remove_redundant\": word,  # No change if no duplicates\n",
    "        \"counting\": str(len(word))  # Count letters\n",
    "    }\n",
    "    \n",
    "    return fallback_results.get(transform_type, word)\n",
    "\n",
    "def format_sequence(seq):\n",
    "    \"\"\"Format a sequence for display\"\"\"\n",
    "    if isinstance(seq, list):\n",
    "        return \"[\" + \" \".join(seq) + \"]\"\n",
    "    elif isinstance(seq, str):\n",
    "        return seq\n",
    "    else:\n",
    "        return str(seq)\n",
    "\n",
    "def check_correctness(response, expected_str, transform_type, input_str=None):\n",
    "    \"\"\"\n",
    "    Check if the model's response contains the correct answer by looking for the\n",
    "    \"Answer: \" pattern and comparing the provided answer with the expected output.\n",
    "    \n",
    "    Args:\n",
    "        response (str): The full response from the model\n",
    "        expected_str (str): The expected output string\n",
    "        transform_type (str): The type of transformation applied\n",
    "        input_str (str, optional): The original input string\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if the expected output matches the answer, False otherwise\n",
    "    \"\"\"\n",
    "    # Handle empty responses\n",
    "    if not response or not expected_str:\n",
    "        return False\n",
    "    \n",
    "    # Try to extract the result after \"Answer: \" if present\n",
    "    extracted_answer = None\n",
    "    if \"answer:\" in response.lower():\n",
    "        # Split by \"Answer:\" and take the content after it\n",
    "        parts = response.lower().split(\"answer:\")\n",
    "        if len(parts) > 1:\n",
    "            extracted_answer = parts[1].strip()\n",
    "            \n",
    "            # If there are multiple lines after \"Answer:\", take just the first line\n",
    "            lines = extracted_answer.split('\\n')\n",
    "            extracted_answer = lines[0].strip()\n",
    "    \n",
    "    # If we couldn't extract an answer using the marker, return False\n",
    "    if not extracted_answer:\n",
    "        return False\n",
    "    \n",
    "    # Clean both strings for comparison\n",
    "    clean_answer = extracted_answer.replace('[', '').replace(']', '').replace('\"', '').replace(\"'\", '').strip()\n",
    "    clean_expected = expected_str.replace('[', '').replace(']', '').replace('\"', '').replace(\"'\", '').strip()\n",
    "    \n",
    "    # For \"remove_redundant\" transformation - must be exact match, not substring\n",
    "    if transform_type == 'remove_redundant':\n",
    "        # Remove spaces for comparison\n",
    "        no_space_answer = clean_answer.replace(' ', '')\n",
    "        no_space_expected = clean_expected.replace(' ', '')\n",
    "        \n",
    "        # Check if the answer is exactly the expected result\n",
    "        return no_space_answer.lower() == no_space_expected.lower()\n",
    "    \n",
    "    # For counting transformation, extract digits\n",
    "    if transform_type == 'counting':\n",
    "        # If expected is a number, extract numbers from the answer\n",
    "        if clean_expected.isdigit():\n",
    "            import re\n",
    "            numbers = re.findall(r'\\d+', clean_answer)\n",
    "            return clean_expected in numbers\n",
    "    \n",
    "    # For other transformations\n",
    "    # Remove all spaces for comparison\n",
    "    no_space_answer = clean_answer.replace(' ', '')\n",
    "    no_space_expected = clean_expected.replace(' ', '')\n",
    "    \n",
    "    # Exact match after normalizing spaces\n",
    "    if no_space_answer.lower() == no_space_expected.lower():\n",
    "        return True\n",
    "        \n",
    "    # Special case for sequences where spaces matter\n",
    "    spaced_expected = ' '.join(list(no_space_expected.lower()))\n",
    "    if clean_answer.lower() == spaced_expected:\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def manage_context(context, new_user_msg, new_assistant_msg, max_size=8, has_ordinal=False):\n",
    "    \"\"\"Manage context window size, keeping system message, latest ordinal rule, and recent exchanges\"\"\"\n",
    "    # Add new messages\n",
    "    context.append({\"role\": \"user\", \"content\": new_user_msg})\n",
    "    context.append({\"role\": \"assistant\", \"content\": new_assistant_msg})\n",
    "    \n",
    "    # If we exceed max size, intelligently manage what to keep\n",
    "    if len(context) > max_size:\n",
    "        system_msg = context[0] if context and context[0][\"role\"] == \"system\" else None\n",
    "        \n",
    "        # Find the most recent message pair that contains an ordinal word\n",
    "        latest_ordinal_pair = None\n",
    "        latest_ordinal_index = -1\n",
    "        \n",
    "        # Search backwards through user messages for ordinal words\n",
    "        for i in range(len(context) - 2, 0, -2):  # Step by 2, looking at user messages only\n",
    "            if i < len(context) and context[i][\"role\"] == \"user\":\n",
    "                user_msg = context[i][\"content\"].lower()\n",
    "                if any(word in user_msg for word in ORDINAL_WORDS):\n",
    "                    latest_ordinal_pair = (context[i], context[i+1])  # user + assistant pair\n",
    "                    latest_ordinal_index = i\n",
    "                    break\n",
    "        \n",
    "        # If we have ordinal words to preserve\n",
    "        if latest_ordinal_pair:\n",
    "            # Keep: system message + latest ordinal pair + most recent exchanges\n",
    "            other_messages = []\n",
    "            for i, msg in enumerate(context[1:], 1):  # Skip system message\n",
    "                # Skip the ordinal pair we're preserving\n",
    "                if i != latest_ordinal_index and i != latest_ordinal_index + 1:\n",
    "                    other_messages.append(msg)\n",
    "            \n",
    "            # Calculate how many recent messages we can keep\n",
    "            reserved_slots = 1 + 2  # system + ordinal pair\n",
    "            available_slots = max_size - reserved_slots\n",
    "            recent_messages = other_messages[-available_slots:] if available_slots > 0 else []\n",
    "            \n",
    "            # Reconstruct context: system + ordinal pair + recent messages\n",
    "            context = [system_msg] + list(latest_ordinal_pair) + recent_messages\n",
    "        else:\n",
    "            # No ordinal words found, use normal context management\n",
    "            if system_msg:\n",
    "                recent_messages = context[-(max_size-1):]\n",
    "                context = [system_msg] + recent_messages\n",
    "            else:\n",
    "                context = context[-max_size:]\n",
    "    \n",
    "    return context\n",
    "\n",
    "def main():\n",
    "    # Load dataset and meta answers\n",
    "    with open('alphabet_dataset.json', 'r') as f:\n",
    "        full_dataset = json.load(f)\n",
    "    \n",
    "    meta_answers = load_alphabet_meta_answers()\n",
    "    \n",
    "    print(f\"Loaded dataset with {len(full_dataset)} items\")\n",
    "    \n",
    "    # Test configuration\n",
    "    base_transform = 'succ'  # Default transformation (Rule 1)\n",
    "    current_transform = base_transform\n",
    "    num_trials = min(400, len(full_dataset))\n",
    "    \n",
    "    # Initialize context with system message only\n",
    "    system_prompt = create_system_prompt()\n",
    "    context = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "    \n",
    "    # Results tracking\n",
    "    all_results = []\n",
    "    correct_answers = 0\n",
    "    incorrect_answers = 0\n",
    "    \n",
    "    print(f\"\\nTesting alphabet game with meta-rules on {num_trials} items...\")\n",
    "    print(f\"Starting with base transformation: Rule {TRANSFORM_TYPES[base_transform]['rule_number']} ({TRANSFORM_TYPES[base_transform]['name']})\")\n",
    "    \n",
    "    for i in range(num_trials):\n",
    "        # Select random item\n",
    "        item = random.choice(full_dataset)\n",
    "        \n",
    "        # Maybe insert ordinal words\n",
    "        original_input = item['input']\n",
    "        if any(word in str(original_input).lower() for word in ORDINAL_WORDS):\n",
    "            found_word = next(word for word in ORDINAL_WORDS if word in str(original_input).lower())\n",
    "            modified_input = original_input  # Keep the original input\n",
    "            inserted_words = [found_word]    # But mark it as having an ordinal word\n",
    "        else:\n",
    "            # Only do random insertion if no natural ordinal found\n",
    "            modified_input, inserted_words = insert_ordinal_word(original_input)\n",
    "        \n",
    "        # Update current transformation based on ordinal words\n",
    "        if inserted_words:\n",
    "            current_transform = determine_active_transform(inserted_words, current_transform)\n",
    "            rule_num = TRANSFORM_TYPES[current_transform]['rule_number']\n",
    "            print(f\"\\n🔄 Meta-rule activation! '{inserted_words[-1]}' detected -> Switch to Rule {rule_num} ({TRANSFORM_TYPES[current_transform]['name']})\")\n",
    "        \n",
    "        # Get expected output\n",
    "        if inserted_words:\n",
    "            # For ordinal words, use meta-rule transformations\n",
    "            expected_output = get_transform_result_for_ordinal(inserted_words[-1], current_transform, meta_answers)\n",
    "        else:\n",
    "            # Use regular transformation from dataset\n",
    "            expected_output = item['transformations'][current_transform]\n",
    "        \n",
    "        # Format for display\n",
    "        input_str = format_sequence(modified_input)\n",
    "        expected_str = format_sequence(expected_output)\n",
    "        rule_number = TRANSFORM_TYPES[current_transform]['rule_number']\n",
    "        \n",
    "        print(f\"\\n----- Trial {i+1}/{num_trials} -----\")\n",
    "        print(f\"Input: {input_str}\")\n",
    "        if inserted_words:\n",
    "            print(f\"Ordinal words detected: {inserted_words}\")\n",
    "        print(f\"Active transformation: Rule {rule_number} ({TRANSFORM_TYPES[current_transform]['name']})\")\n",
    "        print(f\"Expected output: {expected_str}\")\n",
    "        \n",
    "        # Create the transformation task - NO meta-rule explanation in user prompt, only the task\n",
    "        current_task = f\"Transform: {input_str}\"\n",
    "        \n",
    "        # Create result object\n",
    "        result = {\n",
    "            \"trial_num\": i+1,\n",
    "            \"original_input\": original_input,\n",
    "            \"modified_input\": modified_input,\n",
    "            \"inserted_words\": inserted_words,\n",
    "            \"active_transform\": current_transform,\n",
    "            \"rule_number\": rule_number,\n",
    "            \"expected_output\": expected_output,\n",
    "            \"input_str\": input_str,\n",
    "            \"expected_str\": expected_str,\n",
    "            \"transform_type\": current_transform,\n",
    "            \"context_length\": len(context),\n",
    "            \"is_duplicated\": item.get('has_duplicates', False),\n",
    "            \"data_type\": \"word\" if isinstance(original_input, str) else \"sequence\",\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        # Call OpenAI API\n",
    "        try:\n",
    "            print(\"Calling API...\")\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Prepare messages\n",
    "            current_messages = context + [{\"role\": \"user\", \"content\": current_task}]\n",
    "            \n",
    "            # Call OpenAI API\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=current_messages,\n",
    "                max_completion_tokens = 1000,\n",
    "                temperature=1\n",
    "            )\n",
    "            \n",
    "            end_time = time.time()\n",
    "            response_time = end_time - start_time\n",
    "            response_text = response.choices[0].message.content\n",
    "            \n",
    "            print(f\"GPT Response: {response_text}\")\n",
    "            \n",
    "            # Check correctness\n",
    "            is_correct = check_correctness(response_text, expected_str, current_transform, input_str)\n",
    "\n",
    "            \n",
    "            # Update result\n",
    "            result.update({\n",
    "                \"response\": response_text,\n",
    "                \"response_time\": response_time,\n",
    "                \"is_correct\": is_correct\n",
    "            })\n",
    "            \n",
    "            if is_correct:\n",
    "                print(\"✓ Correct!\")\n",
    "                correct_answers += 1\n",
    "            else:\n",
    "                print(f\"✗ Incorrect. The correct answer is: {expected_str}\")\n",
    "                incorrect_answers += 1\n",
    "            \n",
    "            # Update context with sliding window, preserving ordinal words\n",
    "            context = manage_context(context, current_task, response_text, MAX_CONTEXT_SIZE, bool(inserted_words))\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = str(e)\n",
    "            print(f\"Error: {error_msg}\")\n",
    "            result[\"error\"] = error_msg\n",
    "            result[\"is_correct\"] = False\n",
    "            incorrect_answers += 1\n",
    "        \n",
    "        all_results.append(result)\n",
    "        time.sleep(0.5)  # Rate limiting for OpenAI API\n",
    "    \n",
    "    # Print final results\n",
    "    print(\"\\n===== Final Results =====\")\n",
    "    print(f\"Total trials: {num_trials}\")\n",
    "    print(f\"Correct answers: {correct_answers} ({correct_answers/num_trials*100:.1f}%)\")\n",
    "    print(f\"Incorrect answers: {incorrect_answers} ({incorrect_answers/num_trials*100:.1f}%)\")\n",
    "    \n",
    "    # Save results\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    results_dir = \"results\"\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    # Save JSON\n",
    "    json_filename = f\"{results_dir}/gpto3_alphabet_game_meta_{timestamp}.json\"\n",
    "    with open(json_filename, 'w') as f:\n",
    "        json.dump(all_results, f, indent=2)\n",
    "    print(f\"Results saved to {json_filename}\")\n",
    "    \n",
    "    # Save NPZ\n",
    "    npz_filename = f\"{results_dir}/gpto3_alphabet_game_meta_{timestamp}.npz\"\n",
    "    np.savez(\n",
    "        npz_filename,\n",
    "        trial_nums=np.array([r[\"trial_num\"] for r in all_results]),\n",
    "        correctness=np.array([1 if r[\"is_correct\"] else 0 for r in all_results]),\n",
    "        context_lengths=np.array([r[\"context_length\"] for r in all_results]),\n",
    "        response_times=np.array([r.get(\"response_time\", 0) for r in all_results]),\n",
    "        data_types=np.array([1 if r[\"data_type\"] == \"word\" else 0 for r in all_results]),\n",
    "        has_duplicates=np.array([1 if r[\"is_duplicated\"] else 0 for r in all_results]),\n",
    "        has_ordinals=np.array([1 if r[\"inserted_words\"] else 0 for r in all_results]),\n",
    "        transform_type=current_transform,\n",
    "        accuracy=correct_answers/num_trials,\n",
    "        timestamp=timestamp\n",
    "    )\n",
    "    print(f\"Results also saved to {npz_filename}\")\n",
    "    print(\"\\nDone testing!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
